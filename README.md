# üìä Data Pipeline - Receita Federal de Empresas

Pipeline de dados para processamento de informa√ß√µes cadastrais de empresas brasileiras da Receita Federal.

## üèóÔ∏è Arquitetura

![alt text](https://file%2B.vscode-resource.vscode-cdn.net/Users/patriciatozi/Documents/Projetos/GitHub/receita-federal-empresas/documentation/src/Arquitetura%20-%20Receita%20Federal.png?version%3D1758221667306)

## üìã Funcionalidades

- ‚úÖ Ingest√£o de dados dos arquivos ZIP da Receita Federal
- ‚úÖ Processamento em camadas (Bronze ‚Üí Silver ‚Üí Gold)
- ‚úÖ Valida√ß√£o de dados com Pandera
- ‚úÖ Monitoramento de qualidade com m√©tricas em PostgreSQL
- ‚úÖ Dashboards no Apache Superset
- ‚úÖ Orquestra√ß√£o com Apache Airflow

## üõ†Ô∏è Tecnologias
- Python 3.12 - Processamento de dados
- Pandas - Manipula√ß√£o de dados
- Airflow - Orquestra√ß√£o de pipelines
- Pandera - Valida√ß√£o de dados
- PostgreSQL - Armazenamento de dados e m√©tricas
- Superset - Visualiza√ß√£o de dados
- Docker - Containeriza√ß√£o

## üìÅ Estrutura do Projeto

``` sh
receita-federal-empresas/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îî‚îÄ‚îÄ main_pipeline.py          # DAG principal do Airflow
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion/           # Ingest√£o de dados brutos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ companies.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ partners.py
‚îÇ   ‚îú‚îÄ‚îÄ data_processing/          # Processamento das camadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ companies.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ partners.py
‚îÇ   ‚îú‚îÄ‚îÄ data_refinement/          # Camada gold
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ companies_detail.py
‚îÇ   ‚îî‚îÄ‚îÄ data_quality/             # Valida√ß√µes com Pandera
‚îÇ       ‚îú‚îÄ‚îÄ bronze_validation.py
‚îÇ       ‚îú‚îÄ‚îÄ silver_validation.py
‚îÇ       ‚îî‚îÄ‚îÄ gold_validation.py
‚îú‚îÄ‚îÄ docker-compose.yml            # Orquestra√ß√£o de containers
‚îú‚îÄ‚îÄ Dockerfile                    # Imagem customizada
‚îú‚îÄ‚îÄ requirements.txt              # Depend√™ncias Python
‚îî‚îÄ‚îÄ .env                          # Vari√°veis de ambiente
```

## üöÄ Setup do Ambiente
### Pr√©-requisitos
- Docker 20.10+
- Docker Compose 2.0+
- 8GB RAM recomendado

### 1. Clone o reposit√≥rio
``` sh
git clone https://github.com/seu-usuario/receita-federal-empresas.git
cd receita-federal-empresas
```
### 2. Configure as vari√°veis de ambiente
``` sh
cp .env.example .env
# Edite o .env com suas configura√ß√µes
```
### 3. Execute os containers
``` sh
# Inicie todos os servi√ßos
docker-compose up -d

# Ou construa as imagens e inicie
docker-compose build
docker-compose up -d
```
### 4. Acesse as interfaces
- Airflow: http://localhost:8080
    - Usu√°rio: airflow
    - Senha: airflow
- Superset: http://localhost:8088
    - Usu√°rio: admin
    - Senha: admin

## üìä Camadas de Dados

### ü•â Bronze Layer (Raw)
- Dados brutos ingeridos da Receita Federal
- Formato original preservado
- Valida√ß√µes b√°sicas de formato

### ü•à Silver Layer (Cleaned)
- Dados limpos e tratados
- Schema validation com Pandera
- Padroniza√ß√£o de formatos

### ü•á Gold Layer (Business)
- Dados enriquecidos para an√°lise
- M√©tricas de neg√≥cio
- Agrega√ß√µes e transforma√ß√µes

## ‚úÖ Data Quality Checks

### Valida√ß√µes Implementadas
#### Camada Silver:
- ‚úÖ CNPJ com 14 d√≠gitos
- ‚úÖ C√≥digo de porte v√°lido (00, 01, 03, 05)
- ‚úÖ Natureza jur√≠dica dentro da faixa esperada
- ‚úÖ Capital social n√£o negativo
#### Camada Gold:
- ‚úÖ Quantidade de s√≥cios > 0
- ‚úÖ Flags booleanas consistentes
- ‚úÖ Regras de neg√≥cio aplicadas

### M√©tricas Monitoradas
``` sql
-- Exemplo de m√©tricas coletadas
SELECT * FROM data_quality_metrics 
WHERE table_name = 'companies' 
ORDER BY created_at DESC 
LIMITE 10;
```

## üìà Dashboards no Superset

TBD

## üîß Comandos √öteis

### Docker Compose
``` sh
# Ver status dos containers
docker-compose ps

# Logs do Airflow
docker-compose logs airflow-scheduler

# Executar comando em container espec√≠fico
docker-compose exec airflow-scheduler airflow dags list

# Parar todos os servi√ßos
docker-compose down

# Parar e remover volumes
docker-compose down -v
```
### Airflow
``` sh
# Listar DAGs
docker-compose exec airflow-scheduler airflow dags list

# Trigger manual da DAG
docker-compose exec airflow-scheduler airflow dags trigger main_pipeline

# Ver logs de uma task
docker-compose exec airflow-webserver airflow tasks logs main_pipeline bronze_companies
```
### Desenvolvimento
``` sh
# Instalar depend√™ncias localmente
pip install -r requirements.txt

# Executar script individualmente
python scripts/data_ingestion/companies.py

# Testar valida√ß√µes
python scripts/data_quality/silver_validation.py
```

## üìù Pr√≥ximos Passos
### Melhorias Futuras
-Adicionar testes unit√°rios
- Implementar alertas de qualidade
- Adicionar mais fontes de dados
- Otimizar performance de queries
- Implementar particionamento de dados
### Customiza√ß√£o
- Editar scripts/data_processing/ para novas transforma√ß√µes
- Modificar scripts/data_quality/ para novas valida√ß√µes
- Ajustar dags/main_pipeline.py para alterar o fluxo
- Customizar queries no Superset para novos dashboards

## ü§ù Contribui√ß√£o
1. Fork o projeto
2. Crie uma branch para sua feature (git checkout -b feature/AmazingFeature)
3. Commit suas mudan√ßas (git commit -m 'Add some AmazingFeature')
4. Push para a branch (git push origin feature/AmazingFeature)
5. Abra um Pull Request

## üìÑ Licen√ßa
Este projeto est√° sob a licen√ßa MIT. Veja o arquivo LICENSE para detalhes.